GPU 튜닝 가이드 및 성능 비교
===========================================

작동 원리
-------------

LightGBM에서 학습 동안의 주요 계산비용은 특성변수 히스토그램들을 형성하는 데 발생합니다. 본 실험은 효율적인 알고리즘을 사용하여 이 과정을 가속화 합니다. 
적용방법은 매우 규격화 되어있으며, 모든 학습 과제들 (분류, 랭킹, 회귀 등)에서 작동합니다. 또한, GPU 가속화는 병렬학습 환경에서도 작동합니다. 
GPU 알고리즘 적용은 OpenCL (개방형 범용 병렬 컴퓨팅 프레임워크)에 기반하고 있으며 다양한 범주의 GPU들과 동작할 수 있습니다. 

지원되는 하드웨어
------------------

AMD Graphics Core Next (GCN) 아키텍처와 NVIDIA Maxwell 및 Pascal 아키텍처를 대상으로 합니다.
2012년 이후에 출시된 대부분의 AMD GPU와 2014년 이후에 출시된 NVIDIA GPU는 지원될 것입니다. 다음 GPU에서 GPU구현을 테스트했습니다:

- Ubuntu 16.10에서 AMDGPU-pro 드라이버 16.60을 사용한 AMD RX 480

- Ubuntu 16.10에서 fglrx 드라이버 15.302.2301을 사용한 AMD R9 280X (Radeon HD 7970으로도 알려짐)

- Ubuntu 16.10에서 드라이버 375.39와 CUDA 8.0을 사용한 NVIDIA GTX 1080

- Ubuntu 16.04에서 드라이버 367.48과 CUDA 8.0을 사용한 NVIDIA Titan X (Pascal)

- Ubuntu 16.04에서 드라이버 375.39와 CUDA 7.5을 사용한 NVIDIA Tesla M40

다음 하드웨어 사용은 권장되지 않습니다:

- NVIDIA Kepler (K80, K40, K20, 대부분의 GeForce GTX 700 시리즈 GPU) 이전의 NVIDIA GPU. 이들은 로컬 메모리 공간에서 하드웨어 원자 연산을 지원하지 않으므로 히스토그램 구성이 느릴 것입니다.

- Radeon HD 6xxx 시리즈 및 이전 GPU를 포함한 AMD VLIW4 기반 GPU. 이러한 GPU는 여러 해 동안 단종되었으며 현재는 거의 사용되지 않습니다.


GPU에서 좋은 속도 향상을 얻는 방법
----------------------------------

#.  설정이 올바른지 확인하기 위해 우리가 좋은 속도 향상을 검증한 몇 가지 데이터 세트를 실행하고자 합니다 (Higgs, epsilon, Bosch 등 포함).
    여러 개의 GPU를 가지고 있다면, 원하는 GPU를 사용하도록 ``gpu_platform_id`` 와 ``gpu_device_id`` 를 설정해야 합니다.
    또한 (특히 공용 컴퓨터를 사용할 때) 시스템이 비활성 상태인지 확인하세요. 그러면 정확한 성능 측정을 얻을 수 있습니다.

#.  GPU는 대규모의 밀집 데이터셋에서 가장 잘 작동합니다. 데이터셋이 너무 작으면 GPU에서 계산하는 데 비효율적일 수 있으며, 데이터 전송 비용(오버헤드)이 상당할 수 있습니다.
    범주형 특성변수가 있는 경우, ``categorical_column`` 옵션을 사용하여 이를 직접 LightGBM에 입력하십시오. 이를 원-핫 인코딩 방식으로 변환하지 마세요.

#.  GPU를 효과적으로 사용하기 위해 더 작은 바이너리(bin) 수를 사용하는 것이 좋습니다. 
    ``max_bin=63`` 설정을 권장하며, 이는 대규모 데이터셋에서 학습 정확도에 미치는 영향이 거의 없을 뿐만 아니라, 빈 크기 (bin size)를 기본설정값인 255로 할 때보다 GPU 학습이 훨씬 빠를 수 있습니다.
    일부 데이터셋의 경우, 15개의 빈을 사용하는 것도 충분할 수 있습니다 (``max_bin=15``); 15개의 빈을 사용하면 GPU 성능이 최대화됩니다. 실행 로그를 확인하고 원하는 바이너리 수가 사용되었는지 확인하십시오.

#.   가능한 경우, 싱글 프리시전 학습 (``gpu_use_dp=false``)을 사용하십시오. 왜냐하면 대부분의 GPU (특히 NVIDIA의 일반 소비자용 GPU)는 더블 프리시전 성능이 좋지 않기 때문입니다.


성능 비교
----------------------

아래 데이터셋을 사용하여 GPU 속도향상에 따른 학습 성능을 평가하였습니다.

+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| **데이터** |    **수행과제**    | **링크** | **#Examples** | **#특성변수(Feature)** | **비고**                                       |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| Higgs      | 이진 분류          | `link1`_ | 10,500,000    | 28                     | 마지막 샘플 50만개는 테스트셋으로 사용됨       |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| Epsilon    | 이진 분류          | `link2`_ | 400,000       | 2,000                  | 제공되는 테스트셋을 사용함                     |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| Bosch      | 이진 분류          | `link3`_ | 1,000,000     | 968                    | 제공되는 테스트셋을 사용함                     |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| Yahoo LTR  | 랭킹 학습          | `link4`_ | 473,134       | 700                    | set1.train은 학습, set1.test은 테스트에 사용됨 |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| MS LTR     | 랭킹 학습          | `link5`_ | 2,270,296     | 137                    | {S1,S2,S3}은 학습, {S5}은 테스트에 사용됨      |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+
| Expo       | 이진 분류 (범주형) | `link6`_ | 11,000,000    | 700                    | 마지막 샘플 100만개는 테스트셋으로 사용됨      |
+------------+--------------------+----------+---------------+------------------------+------------------------------------------------+

LightGBM GPU 학습의 성능을 평가하기 위해 아래와 같은 하드웨어를 사용했습니다.
CPU 기준은 **28코어의 하이엔드 듀얼 소켓 Haswell-EP Xeon (high-end dual socket Haswell-EP Xeon) 서버**입니다.
GPU로는 동일한 서버에 설치된 예산형 GPU (RX 480)와 주류형 GPU (GTX 1080)를 사용했습니다.
**사용한 GPU는 시장에서 가장 우수한 GPU는 아니라는 점**을 감안해야 합니다.
더 좋은 GPU (AMD RX 580, NVIDIA GTX 1080 Ti, Titan X Pascal, Titan Xp, Tesla P100 등)를 사용하면 더 높은 속도 향상을 얻을 수 있습니다.

+--------------------------------+----------------+------------------+---------------+
| Hardware                       | Peak FLOPS     | Peak Memory BW   | Cost (MSRP)   |
+================================+================+==================+===============+
| AMD Radeon RX 480              | 5,161 GFLOPS   | 256 GB/s         | $199          |
+--------------------------------+----------------+------------------+---------------+
| NVIDIA GTX 1080                | 8,228 GFLOPS   | 320 GB/s         | $499          |
+--------------------------------+----------------+------------------+---------------+
| 2x Xeon E5-2683v3 (28 cores)   | 1,792 GFLOPS   | 133 GB/s         | $3,692        |
+--------------------------------+----------------+------------------+---------------+

CPU 벤치마킹 중에는 CPU의 28개 물리적인 코어만 사용하고, 하이퍼스레딩 코어는 사용하지 않았습니다.
너무 많은 스레드를 사용하는 것이 실제로 성능을 떨어뜨린다는 것을 발견했기 때문입니다.
본 실험에서 설정한 학습 구성은 아래와 같습니다:

::

    max_bin = 63
    num_leaves = 255
    num_iterations = 500
    learning_rate = 0.1
    tree_learner = serial
    task = train
    is_training_metric = false
    min_data_in_leaf = 1
    min_sum_hessian_in_leaf = 100
    ndcg_eval_at = 1,3,5,10
    device = gpu
    gpu_platform_id = 0
    gpu_device_id = 0
    num_thread = 28

``min_sum_hessian_in_leaf=5``. 본 실험은 Bosch 데이터셋을 제외하고는 위와 같은 구성으로 진행되었습니다. Bosch 데이터로는 더 작은 ``learning_rate=0.015`` 그리고 ``min_sum_hessian_in_leaf=5``로 설정하였습니다. 
모든 GPU 학습에서 빈 (#bin)의 최대개수를 다양화 하며 실험했습니다 (255, 63 and 15).
The GPU implementation is from commit `0bb4a82`_ of LightGBM, when the GPU support was just merged in.
GPU 구현은 GPU 지원이 막 병합된 시점인 LightGBM의 커밋 `0bb4a82`_ 을 기반으로 합니다. 

아래 표는 CPU와 GPU 러너 (GPU learner)가 500번의 이터레이션 후 도달한 테스트셋 상에서의 정확도입니다. 
같은 개수의 빈(bin)을 가졌다는 조건 하에서의 GPU는, 싱글 프리시전 계산임에도 불구하고 CPU에서 비슷한 수준의 정확도를 보입니다. 

+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
|                           | CPU 255 bins   | CPU 63 bins   | CPU 15 bins   | GPU 255 bins   | GPU 63 bins   | GPU 15 bins   |
+===========================+================+===============+===============+================+===============+===============+
| Higgs AUC                 | 0.845612       | 0.845239      | 0.841066      | 0.845612       | 0.845209      | 0.840748      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Epsilon AUC               | 0.950243       | 0.949952      | 0.948365      | 0.950057       | 0.949876      | 0.948365      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Yahoo-LTR NDCG\ :sub:`1`  | 0.730824       | 0.730165      | 0.729647      | 0.730936       | 0.732257      | 0.73114       |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Yahoo-LTR NDCG\ :sub:`3`  | 0.738687       | 0.737243      | 0.736445      | 0.73698        | 0.739474      | 0.735868      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Yahoo-LTR NDCG\ :sub:`5`  | 0.756609       | 0.755729      | 0.754607      | 0.756206       | 0.757007      | 0.754203      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Yahoo-LTR NDCG\ :sub:`10` | 0.79655        | 0.795827      | 0.795273      | 0.795894       | 0.797302      | 0.795584      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Expo AUC                  | 0.776217       | 0.771566      | 0.743329      | 0.776285       | 0.77098       | 0.744078      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| MS-LTR NDCG\ :sub:`1`     | 0.521265       | 0.521392      | 0.518653      | 0.521789       | 0.522163      | 0.516388      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| MS-LTR NDCG\ :sub:`3`     | 0.503153       | 0.505753      | 0.501697      | 0.503886       | 0.504089      | 0.501691      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| MS-LTR NDCG\ :sub:`5`     | 0.509236       | 0.510391      | 0.507193      | 0.509861       | 0.510095      | 0.50663       |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| MS-LTR NDCG\ :sub:`10`    | 0.527835       | 0.527304      | 0.524603      | 0.528009       | 0.527059      | 0.524722      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+
| Bosch AUC                 | 0.718115       | 0.721791      | 0.716677      | 0.717184       | 0.724761      | 0.717005      |
+---------------------------+----------------+---------------+---------------+----------------+---------------+---------------+

아래 차트는 500번 이터레이션 소요시간 (wall clock time)을 기록한 결과를 나타냅니다:

.. image:: ./_static/images/gpu-performance-comparison.png
   :align: center
   :target: ./_static/images/gpu-performance-comparison.png
   :alt: A performance chart which is a record of the wall clock time after 500 iterations on G P U for Higgs, epsilon, Bosch, Microsoft L T R, Expo and Yahoo L T R and bin size of 63 performs comparatively better.

GPU를 사용하는 경우, 빈 크기 (bin size)는 255 보다는 63을 권장합니다. 왜냐하면 이는 정확도에 거의 영향을 주지 않으면서도 상당한 학습 속도 향상을 가져오기 때문입니다. 
CPU에서는, Higgs 케이스에서 알 수 있듯이 더 작은 빈 크기를 사용하는 것으로는 아주 작은 성능 향상 정도만 가능하며, 가끔은 학습속도를 저해합니다 (같은 속도저하를 GCC 버전이 다른 두 개의 기계에서 재현할 수 있습니다).   
위 실험에서, GPU는 대규모의 밀집된 데이터셋에서 엄청난 속도향상을 가져옴을 확인했습니다. 
심지어 더 작고 희소(sparse)행렬 형태의 데이터셋에서도,  *예산형 (budget)* GPU가 여전히 28코어 Haswell 서버와 비기거나 더 빠를 수 있습니다. 

메모리 사용량
------------

다음 표는 ``nvidia-smi`` 에 의해 보고된 63개의 빈으로 학습하는 동안의 GPU 메모리 사용량입니다. 
가장 큰 데이터셋도 약 1GB의 GPU 메모리만 사용하므로, GPU 구현이 Bosch나 Epsilon보다 10배 이상 큰 대규모 데이터셋에 확장될 수 있다는 것을 나타냅니다.
또한, 일반적으로 더 큰 데이터셋 (Epsilon이나 Bosch와 같이 더 많은 GPU 메모리를 사용하는 경우)이 더 나은 속도향상을 보인다는 것을 확인할 수 있으며, 이는 데이터셋이 작을 때 GPU 함수를 호출하는 오버헤드가 상당하기 때문입니다.

+-------------------------+---------+-----------+---------+----------+--------+-------------+
| Datasets                | Higgs   | Epsilon   | Bosch   | MS-LTR   | Expo   | Yahoo-LTR   |
+=========================+=========+===========+=========+==========+========+=============+
| GPU Memory Usage (MB)   | 611     | 901       | 1067    | 413      | 405    | 291         |
+-------------------------+---------+-----------+---------+----------+--------+-------------+

추가 참고자료
---------------

다음 자료들에서 GPU 알고리즘과 벤치마크에 대한 더 상세한 정보를 얻으실 수 있습니다:

Huan Zhang, Si Si and Cho-Jui Hsieh. `GPU Acceleration for Large-scale Tree Boosting`_. SysML Conference, 2018.

.. _link1: https://archive.ics.uci.edu/ml/datasets/HIGGS

.. _link2: http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html

.. _link3: https://www.kaggle.com/c/bosch-production-line-performance/data

.. _link4: https://webscope.sandbox.yahoo.com/catalog.php?datatype=c

.. _link5: http://research.microsoft.com/en-us/projects/mslr/

.. _link6: http://stat-computing.org/dataexpo/2009/

.. _0bb4a82: https://github.com/microsoft/LightGBM/commit/0bb4a82

.. _GPU Acceleration for Large-scale Tree Boosting: https://arxiv.org/abs/1706.08359
